<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Tech Journal - articles</title><link href="http://lj020326.github.io/" rel="alternate"></link><link href="http://lj020326.github.io/feeds/articles.atom.xml" rel="self"></link><id>http://lj020326.github.io/</id><updated>2018-04-24T12:00:00-04:00</updated><entry><title>Merging Excel Worksheets using Pandas</title><link href="http://lj020326.github.io/blog/2018/04/24/merging-excel-sheets-using-pandas/" rel="alternate"></link><published>2018-04-24T12:00:00-04:00</published><updated>2018-04-24T12:00:00-04:00</updated><author><name>Lee Johnson</name></author><id>tag:lj020326.github.io,2018-04-24:blog/2018/04/24/merging-excel-sheets-using-pandas/</id><summary type="html">
&lt;p&gt;In my prior &lt;a href="http://leeblog.org/blog/2018/04/24/merging-itunes-playlists-using-pandas/"&gt;post&lt;/a&gt;, I loaded 2 playlists in an iTunes text export format into pandas dataframes to match into 1 single dataframe.&lt;/p&gt;
&lt;p&gt;Here I repeat the last step of the prior post assuming that the 2 text files were first imported into excel.&lt;/p&gt;
</summary><category term="jupyter"></category><category term="pandas"></category><category term="excel"></category><category term="merge"></category><category term="join"></category></entry><entry><title>Merging Itunes Playlists using Pandas</title><link href="http://lj020326.github.io/blog/2018/04/24/merging-itunes-playlists-using-pandas/" rel="alternate"></link><published>2018-04-24T12:00:00-04:00</published><updated>2018-04-24T12:00:00-04:00</updated><author><name>Lee Johnson</name></author><id>tag:lj020326.github.io,2018-04-24:blog/2018/04/24/merging-itunes-playlists-using-pandas/</id><summary type="html">
&lt;p&gt;I recently wanted to see how many songs were common between 2 of my iTunes playlists.&lt;/p&gt;
&lt;p&gt;Here I'll take a look at some of the basic questions you can answer with this data.
Later I hope to find the time to dig deeper and ask some more interesting and creative questions â€“ stay tuned!&lt;/p&gt;
</summary><category term="jupyter"></category><category term="pandas"></category><category term="itunes"></category><category term="merge"></category><category term="join"></category></entry><entry><title>Installing Python Packages from a Jupyter Notebook</title><link href="http://lj020326.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/" rel="alternate"></link><published>2017-12-05T09:00:00-05:00</published><updated>2017-12-05T09:00:00-05:00</updated><author><name>Lee Johnson</name></author><id>tag:lj020326.github.io,2017-12-05:blog/2017/12/05/installing-python-packages-from-jupyter/</id><summary type="html">
&lt;p&gt;In software, it's said that &lt;a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/"&gt;all abstractions are leaky&lt;/a&gt;, and this is true for the Jupyter notebook as it is for any other software.
I most often see this manifest itself with the following issue:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I installed &lt;em&gt;package X&lt;/em&gt; and now I can't import it in the notebook. Help!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This issue is a perrennial source of StackOverflow questions (e.g. &lt;a href="https://stackoverflow.com/questions/39007571/running-jupyter-with-multiple-python-and-ipython-paths/"&gt;this&lt;/a&gt;, &lt;a href="https://stackoverflow.com/questions/42500142/importerror-no-module-named-jwt-in-jupyter"&gt;that&lt;/a&gt;, &lt;a href="https://stackoverflow.com/questions/32777807/importerror-no-module-named-cv2-using-jupyter"&gt;here&lt;/a&gt;, &lt;a href="https://stackoverflow.com/questions/42500649/failed-to-import-numpy-as-np-when-i-worked-with-jupyter-notebook"&gt;there&lt;/a&gt;, &lt;a href="https://stackoverflow.com/questions/46634660/jupyter-notebook-wrong-sys-path-and-sys-executable"&gt;another&lt;/a&gt;, &lt;a href="https://stackoverflow.com/questions/44222513/cannot-import-datashader-installed-using-miniconda"&gt;this one&lt;/a&gt;, &lt;a href="https://stackoverflow.com/questions/42178070/jupyter-notebook-importerror-no-module-named-sklearn"&gt;that one&lt;/a&gt;, &lt;a href="https://stackoverflow.com/questions/42034508/fail-pandas-in-python3-jupyter-notebook"&gt;and this&lt;/a&gt;... etc.).&lt;/p&gt;
&lt;p&gt;Fundamentally the problem is usually rooted in the fact that the &lt;strong&gt;Jupyter kernels are disconnected from Jupyter's shell&lt;/strong&gt;; in other words, the installer points to a different Python version than is being used in the notebook.
In the simplest contexts this issue does not arise, but when it does, debugging the problem requires knowledge of the intricacies of the operating system, the intricacies of Python package installation, and the intricacies of Jupyter itself.
In other words, the Jupyter notebook, like all abstractions, is leaky.&lt;/p&gt;
&lt;p&gt;In the wake of several discussions on this topic with colleagues, some online (&lt;a href="https://twitter.com/amuellerml/status/932637063748444160"&gt;exhibit A&lt;/a&gt;, &lt;a href="https://twitter.com/lj020326/status/922846245848150016"&gt;exhibit B&lt;/a&gt;) and some off, I decided to treat this issue in depth here.
This post will address a couple things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;First&lt;/strong&gt;, I'll provide a quick, bare-bones answer to the general question, &lt;em&gt;how can I install a Python package so it works with my jupyter notebook, using pip and/or conda?&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Second&lt;/strong&gt;, I'll dive into some of the background of exactly &lt;em&gt;what&lt;/em&gt; the Jupyter notebook abstraction is doing, how it interacts with the complexities of the operating system, and how you can think about where the "leaks" are, and thus better understand what's happening when things stop working.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Third&lt;/strong&gt;, I'll talk about some ideas the community might consider to help smooth-over these issues, including some changes that the Jupyter, Pip, and Conda developers might consider to ease the cognitive load on users.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This post will focus on two approaches to installing Python packages: &lt;a href="https://pip.pypa.io/en/stable/"&gt;pip&lt;/a&gt; and &lt;a href="https://conda.io/docs/"&gt;conda&lt;/a&gt;.
Other package managers exist (including platform-specific tools like &lt;a href="http://yum.baseurl.org/"&gt;yum&lt;/a&gt;, &lt;a href="https://help.ubuntu.com/community/AptGet/Howto#Package_management_with_APT"&gt;apt&lt;/a&gt;, &lt;a href="https://brew.sh/"&gt;homebrew&lt;/a&gt;, etc., as well as cross-platform tools like &lt;a href="http://enstaller.readthedocs.io/en/latest/"&gt;enstaller&lt;/a&gt;), but I'm less familiar with them and won't be remarking on them further.&lt;/p&gt;
</summary><category term="jupyter"></category><category term="conda"></category><category term="pip"></category></entry><entry><title>Exploring Line Lengths in Python Packages</title><link href="http://lj020326.github.io/blog/2017/11/09/exploring-line-lengths-in-python-packages/" rel="alternate"></link><published>2017-11-09T14:00:00-05:00</published><updated>2017-11-09T14:00:00-05:00</updated><author><name>Lee Johnson</name></author><id>tag:lj020326.github.io,2017-11-09:blog/2017/11/09/exploring-line-lengths-in-python-packages/</id><summary type="html">
&lt;p&gt;This week, Twitter upped their single-tweet character limit from 140 to 280, purportedly based on this &lt;a href="https://blog.twitter.com/engineering/en_us/topics/insights/2017/Our-Discovery-of-Cramming.html"&gt;interesting analysis of tweet lengths&lt;/a&gt; published on Twitter's engineering blog.
The gist of the analysis is this: English language tweets display a roughly log-normal distribution of character counts, except near the 140-character limit, at which the distribution spikes:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://lj020326.github.io/images/tweet_lengths.png" width="500"/&gt;&lt;/p&gt;
&lt;p&gt;The analysis takes this as evidence that twitter users often "cram" their longer thoughts into the 140 character limit, and suggest that a 280-character limit would more naturally accommodate the distribution of people's desired tweet lengths.&lt;/p&gt;
&lt;p&gt;This immediately brought to mind another character limit that many Python programmers face in their day-to-day lives: the 79-character line limit suggested by Python's &lt;a href="https://www.python.org/dev/peps/pep-0008/#maximum-line-length"&gt;PEP8 style guide&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Limit all lines to a maximum of 79 characters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I began to wonder whether popular Python packages (e.g. NumPy, SciPy, Pandas, Scikit-Learn, Matplotlib, AstroPy) display anything similar to what is seen in the distribution of tweet lengths.&lt;/p&gt;
&lt;p&gt;Spoiler alert: they do! And the details of the distribution reveal some insights into the programming habits and stylistic conventions of the communities who write them.&lt;/p&gt;
</summary><category term="python"></category><category term="data"></category><category term="statistics"></category></entry><entry><title>Group-by From Scratch</title><link href="http://lj020326.github.io/blog/2017/03/22/group-by-from-scratch/" rel="alternate"></link><published>2017-03-22T10:00:00-04:00</published><updated>2017-03-22T10:00:00-04:00</updated><author><name>Lee Johnson</name></author><id>tag:lj020326.github.io,2017-03-22:blog/2017/03/22/group-by-from-scratch/</id><summary type="html">
&lt;p&gt;I've found one of the best ways to grow in my scientific coding is to spend time comparing the efficiency of various approaches to implementing particular algorithms that I find useful, in order to build an intuition of the performance of the building blocks of the scientific Python ecosystem.&lt;/p&gt;
&lt;p&gt;In this vein, today I want to take a look at an operation that is in many ways fundamental to data-driven exploration: the group-by, otherwise known as the &lt;a href="https://www.jstatsoft.org/article/view/v040i01"&gt;split-apply-combine&lt;/a&gt; pattern.
An architypical example of a summation group-by is shown in this figure, borrowed from the &lt;a href="http://nbviewer.jupyter.org/github/lj020326/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb"&gt;Aggregation and Grouping&lt;/a&gt; section of the &lt;a href="https://github.com/lj020326/PythonDataScienceHandbook"&gt;Python Data Science Handbook&lt;/a&gt;:&lt;/p&gt;







&lt;p&gt;&lt;img alt="split-apply-combine diagram" src="https://lj020326.github.io/figures/split-apply-combine.svg"/&gt;&lt;/p&gt;







&lt;p&gt;The basic idea is to split the data into groups based on some value, apply a particular operation to the subset of data within each group (often an aggregation), and then combine the results into an output dataframe.
Python users generally turn to the &lt;a href="http://pandas.pydata.org"&gt;Pandas&lt;/a&gt; library for this type of operation, where it is is implemented effiently via a concise object-oriented API:&lt;/p&gt;
</summary><category term="pandas"></category><category term="python"></category><category term="benchmarks"></category></entry><entry><title>Triple Pendulum CHAOS!</title><link href="http://lj020326.github.io/blog/2017/03/08/triple-pendulum-chaos/" rel="alternate"></link><published>2017-03-08T07:00:00-05:00</published><updated>2017-03-08T07:00:00-05:00</updated><author><name>Lee Johnson</name></author><id>tag:lj020326.github.io,2017-03-08:blog/2017/03/08/triple-pendulum-chaos/</id><summary type="html">
&lt;p&gt;Earlier this week a tweet made the rounds which features a video that nicely demonstrates chaotic dynamical systems in action:&lt;/p&gt;
&lt;p&gt;&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p dir="ltr" lang="en"&gt;A visualization of chaos: 41 triple pendulums with very slightly different initial conditions &lt;a href="https://t.co/CTiABFVWHW"&gt;pic.twitter.com/CTiABFVWHW&lt;/a&gt;&lt;/p&gt;â€” Fermat's Library (@fermatslibrary) &lt;a href="https://twitter.com/fermatslibrary/status/838392423063687168"&gt;March 5, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async="" charset="utf-8" src="//platform.twitter.com/widgets.js"&gt;&lt;/script&gt;&lt;p&gt;&lt;em&gt;Edit: a reader pointed out that the original creator of this animation &lt;a href="https://www.reddit.com/r/mathpics/comments/4nd5h1/41_triple_pendulums_with_very_slightly_different/"&gt;posted it on reddit&lt;/a&gt; in 2016.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Naturally, I immediately wondered whether I could reproduce this simlulation in Python.
This post is the result.&lt;/p&gt;
</summary><category term="matplotlib"></category><category term="animation"></category><category term="simulation"></category></entry><entry><title>Reproducible Data Analysis in Jupyter</title><link href="http://lj020326.github.io/blog/2017/03/03/reproducible-data-analysis-in-jupyter/" rel="alternate"></link><published>2017-03-03T07:00:00-05:00</published><updated>2017-03-03T07:00:00-05:00</updated><author><name>Lee Johnson</name></author><id>tag:lj020326.github.io,2017-03-03:blog/2017/03/03/reproducible-data-analysis-in-jupyter/</id><summary type="html">
&lt;p&gt;Jupyter notebooks provide a useful environment for interactive exploration of data. A common question I get, though, is how you can progress from this nonlinear, interactive, trial-and-error style of exploration to a more linear and reproducible analysis based on organized, packaged, and tested code. This series of videos presents a case study in how I personally approach reproducible data analysis within the Jupyter notebook.&lt;/p&gt;
&lt;p&gt;Each video is approximately 5-8 minutes; the videos are
available in a &lt;a href="https://www.youtube.com/playlist?list=PLYCpMb24GpOC704uO9svUrihl-HY1tTJJ"&gt;YouTube Playlist&lt;/a&gt;.
Alternatively, below you can find the videos with some description and links to relevant resources&lt;/p&gt;
</summary><category term="data"></category><category term="pandas"></category><category term="jupyter"></category></entry></feed>